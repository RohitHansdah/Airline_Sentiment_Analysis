{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPpS7lDS7fvn"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqTAYck9W-XT",
        "outputId": "fbc949c3-e2f0-4628-ff0b-61ea43807aff"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpjHcnlWXCLz",
        "outputId": "34610541-ea9c-4b27-b9f2-694834796d95"
      },
      "source": [
        "!pip install texthero"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: texthero in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy<3.0.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (2.2.4)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.2.0)\n",
            "Requirement already satisfied: gensim<4.0,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.0)\n",
            "Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.5.0)\n",
            "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.1.5)\n",
            "Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.2)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.41.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (5.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (1.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (2019.12.20)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (57.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.0.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNEkM1cFT97p",
        "outputId": "11dc6a40-148b-42f4-b9d1-904440bb2c7a"
      },
      "source": [
        "!pip install fastapi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.67.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F6FIbWtT-x1",
        "outputId": "15830993-086c-458e-8615-8975681eb7a4"
      },
      "source": [
        "!pip install uvicorn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (0.12.0)\n",
            "Requirement already satisfied: click>=7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n",
            "Requirement already satisfied: asgiref>=3.3.4 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GcuT7z47d5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6174f5-9520-4b88-f77e-3c0af63cd23c"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import emoji\n",
        "import pickle\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import texthero as hero\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import recall_score\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n",
            "\n",
            "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64I4-Db7Xkwa",
        "outputId": "9b601075-08a7-4a88-8cde-b8097fee94f6"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjWh55877ngu"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "qet-3Bpr5Hha",
        "outputId": "e54fa9b8-0546-4664-a237-188878df3e92"
      },
      "source": [
        "data=pd.read_csv('/content/airline_sentiment_analysis.csv')\n",
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>14633</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11537</th>\n",
              "      <td>14634</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir right on cue with the delays👌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>14635</td>\n",
              "      <td>positive</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>14636</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>14638</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11541 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                               text\n",
              "0               1  ...  @VirginAmerica plus you've added commercials t...\n",
              "1               3  ...  @VirginAmerica it's really aggressive to blast...\n",
              "2               4  ...  @VirginAmerica and it's a really big bad thing...\n",
              "3               5  ...  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4               6  ...  @VirginAmerica yes, nearly every time I fly VX...\n",
              "...           ...  ...                                                ...\n",
              "11536       14633  ...  @AmericanAir my flight was Cancelled Flightled...\n",
              "11537       14634  ...         @AmericanAir right on cue with the delays👌\n",
              "11538       14635  ...  @AmericanAir thank you we got on a different f...\n",
              "11539       14636  ...  @AmericanAir leaving over 20 minutes Late Flig...\n",
              "11540       14638  ...  @AmericanAir you have my money, you change my ...\n",
              "\n",
              "[11541 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dpcVvoy7r9Y"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCwrnguw70Q5"
      },
      "source": [
        "# Check For Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGuSwaz05Tzo",
        "outputId": "33b7f367-9d96-4868-ae78-56bf49c0e0ca"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0           0\n",
              "airline_sentiment    0\n",
              "text                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca8W54Zm76b6"
      },
      "source": [
        "# Categorical Target to Numerical Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9zyzDL25sMK",
        "outputId": "167a6254-4b31-4dd9-a329-0a534246cd25"
      },
      "source": [
        "for i in range(0,len(data)):\n",
        "  if(data['airline_sentiment'][i]==\"positive\"):\n",
        "    data['airline_sentiment'][i]=1\n",
        "  elif(data['airline_sentiment'][i]==\"negative\"):\n",
        "    data['airline_sentiment'][i]=-1\n",
        "  else:\n",
        "    data['airline_sentiment'][i]=0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhtRhoEr8FL4"
      },
      "source": [
        "# Remove unwanted columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farGRxpg5uPS"
      },
      "source": [
        "data=data.drop(columns=['Unnamed: 0'],axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JDBfrA05uUl",
        "outputId": "fa929b03-1340-40cf-e6bc-ae424f8ba074"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11541 entries, 0 to 11540\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   airline_sentiment  11541 non-null  object\n",
            " 1   text               11541 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 180.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ZX0dc-iX5ubN",
        "outputId": "99c41893-c4da-461e-adcc-ca42faa99df5"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11541</td>\n",
              "      <td>11541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>11381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>-1</td>\n",
              "      <td>@united thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>9178</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        airline_sentiment            text\n",
              "count               11541           11541\n",
              "unique                  2           11381\n",
              "top                    -1  @united thanks\n",
              "freq                 9178               5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "WOM-tFDa5uep",
        "outputId": "fee91f23-2964-482b-b781-8f04dfa38081"
      },
      "source": [
        "data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11537</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir right on cue with the delays👌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>1</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11541 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text\n",
              "0                     1  @VirginAmerica plus you've added commercials t...\n",
              "1                    -1  @VirginAmerica it's really aggressive to blast...\n",
              "2                    -1  @VirginAmerica and it's a really big bad thing...\n",
              "3                    -1  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4                     1  @VirginAmerica yes, nearly every time I fly VX...\n",
              "...                 ...                                                ...\n",
              "11536                -1  @AmericanAir my flight was Cancelled Flightled...\n",
              "11537                -1         @AmericanAir right on cue with the delays👌\n",
              "11538                 1  @AmericanAir thank you we got on a different f...\n",
              "11539                -1  @AmericanAir leaving over 20 minutes Late Flig...\n",
              "11540                -1  @AmericanAir you have my money, you change my ...\n",
              "\n",
              "[11541 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfz9KRFt8KBw"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Pxv3O5cZ4L"
      },
      "source": [
        "# Using text pre processing Class to preprocess data (OOPS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74Lh21mbE_o"
      },
      "source": [
        "class text_preprocessing :\n",
        "  def remove_num(text):\n",
        "    res = ''.join([i for i in text if not i.isdigit()])\n",
        "    return res\n",
        "  \n",
        "  def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "\n",
        "  def deEmojify(text):\n",
        "      regrex_pattern = re.compile(pattern = \"[\"\n",
        "          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            \"]+\", flags = re.UNICODE)\n",
        "      return regrex_pattern.sub(r'',text)\n",
        "\n",
        "  def lower_text(data):\n",
        "    data= data.apply(lambda x: x.lower())\n",
        "    return data\n",
        "\n",
        "  def stop_remove(data):\n",
        "    data = hero.remove_stopwords(data)\n",
        "    return data\n",
        "  \n",
        "  def tokenization(text):\n",
        "    tokens = regexp_tokenize(text, \"[\\w']+\")\n",
        "    return tokens\n",
        "  \n",
        "  def lemmatizer(text):\n",
        "    #defining the object for Lemmatization\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()  \n",
        "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
        "    return lemm_text\n",
        "  \n",
        "  def inverse_lemmatizer(text):\n",
        "    res=' '.join(text)\n",
        "    return res"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "JguaKHv2c48U",
        "outputId": "7d137937-b079-4f7d-8c1e-fda5d0f3a92b"
      },
      "source": [
        "df=pd.DataFrame(data)\n",
        "df['clean_msg']=df['text'].apply(lambda x:text_preprocessing.remove_num(x))\n",
        "df['clean_msg']= df['text'].apply(lambda x:text_preprocessing.remove_punctuation(x))\n",
        "df['clean_msg']=df['clean_msg'].apply(lambda x:text_preprocessing.deEmojify(x))\n",
        "df['clean_msg']= text_preprocessing.lower_text(df['clean_msg'])\n",
        "df['clean_msg'] = text_preprocessing.stop_remove(df['clean_msg'])\n",
        "df['token_msg']= df['clean_msg'].apply(lambda x: text_preprocessing.tokenization(x))\n",
        "df['token_msg']= df['clean_msg'].apply(lambda x: text_preprocessing.lemmatizer(x))\n",
        "df['token_msg']= df['clean_msg'].apply(lambda x: text_preprocessing.inverse_lemmatizer(x))\n",
        "df=df.drop(columns=['token_msg'],axis=1)\n",
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_msg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>virginamerica plus youve added commercials   e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>virginamerica  really aggressive  blast obnoxi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>virginamerica    really big bad thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>virginamerica seriously would pay 30  flight  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>virginamerica yes nearly every time  fly vx  e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
              "      <td>americanair  flight  cancelled flightled leavi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11537</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir right on cue with the delays👌</td>\n",
              "      <td>americanair right  cue   delays</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>1</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "      <td>americanair thank   got   different flight  ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "      <td>americanair leaving  20 minutes late flight  w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "      <td>americanair    money  change  flight  dont ans...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11541 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment  ...                                          clean_msg\n",
              "0                     1  ...  virginamerica plus youve added commercials   e...\n",
              "1                    -1  ...  virginamerica  really aggressive  blast obnoxi...\n",
              "2                    -1  ...            virginamerica    really big bad thing  \n",
              "3                    -1  ...  virginamerica seriously would pay 30  flight  ...\n",
              "4                     1  ...  virginamerica yes nearly every time  fly vx  e...\n",
              "...                 ...  ...                                                ...\n",
              "11536                -1  ...  americanair  flight  cancelled flightled leavi...\n",
              "11537                -1  ...                    americanair right  cue   delays\n",
              "11538                 1  ...  americanair thank   got   different flight  ch...\n",
              "11539                -1  ...  americanair leaving  20 minutes late flight  w...\n",
              "11540                -1  ...  americanair    money  change  flight  dont ans...\n",
              "\n",
              "[11541 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOxPa8Daz-76"
      },
      "source": [
        "# Remove Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQNceWIz13q"
      },
      "source": [
        "def remove_num(text):\n",
        "  res = ''.join([i for i in text if not i.isdigit()])\n",
        "  return res"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7J9tMqz6EM"
      },
      "source": [
        "data['clean_msg']=data['text'].apply(lambda x:remove_num(x))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJwZve98YLe"
      },
      "source": [
        "# Remove Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpD59dff5uiH"
      },
      "source": [
        "#defining the function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "#storing the puntuation free text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xTFaia75ukw"
      },
      "source": [
        "data['clean_msg']= data['text'].apply(lambda x:remove_punctuation(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SoNC8V80ZjP"
      },
      "source": [
        "# Remove Emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmyNTVq70JCq"
      },
      "source": [
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoakXyuX0TJY"
      },
      "source": [
        "data['clean_msg']=data['clean_msg'].apply(lambda x:deEmojify(x))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cejmmTu8uda"
      },
      "source": [
        "# Lowering Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-DlUuch8rnM"
      },
      "source": [
        "data['clean_msg']= data['clean_msg'].apply(lambda x: x.lower())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeIYuvtO0nvY"
      },
      "source": [
        "#  Stop Word Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFDnBXPu0lUh"
      },
      "source": [
        "#applying the function\n",
        "data['clean_msg'] = hero.remove_stopwords(data['clean_msg'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UDzFp0W89Wh"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P2vZLLn8rqS"
      },
      "source": [
        "#defining function for tokenization\n",
        "def tokenization(text):\n",
        "    tokens = regexp_tokenize(text, \"[\\w']+\")\n",
        "    return tokens"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOeeZRsR8rtF"
      },
      "source": [
        "#applying function to the column\n",
        "data['token_msg']= data['clean_msg'].apply(lambda x: tokenization(x))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM0_SV0b-EwP"
      },
      "source": [
        "# Lemmitization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euzhlaD4-DEy"
      },
      "source": [
        "#defining the function for lemmatization\n",
        "def lemmatizer(text):\n",
        "    #defining the object for Lemmatization\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()  \n",
        "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
        "    return lemm_text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B3zl-kb-Hwv"
      },
      "source": [
        "data['msg_lemmatized']=data['token_msg'].apply(lambda x:lemmatizer(x))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BErhNl3kGmQ-"
      },
      "source": [
        "def inverse_lemmatizer(text):\n",
        "    res=' '.join(text)\n",
        "    return res"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAkQrrr6Hf_9"
      },
      "source": [
        "data['clean_msg']=data['msg_lemmatized'].apply(lambda x:inverse_lemmatizer(x))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izoavIAnH0Ys"
      },
      "source": [
        "data=data.drop(columns=['token_msg'],axis=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "OxZgGQRTHqPB",
        "outputId": "0f7f25d4-d34d-47c4-a305-b74eb5739d70"
      },
      "source": [
        "data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_msg</th>\n",
              "      <th>msg_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>virginamerica plus youve added commercial expe...</td>\n",
              "      <td>[virginamerica, plus, youve, added, commercial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
              "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>virginamerica really big bad thing</td>\n",
              "      <td>[virginamerica, really, big, bad, thing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
              "      <td>[virginamerica, seriously, would, pay, 30, fli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
              "      <td>[virginamerica, yes, nearly, every, time, fly,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
              "      <td>americanair flight cancelled flightled leaving...</td>\n",
              "      <td>[americanair, flight, cancelled, flightled, le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11537</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir right on cue with the delays👌</td>\n",
              "      <td>americanair right cue delay</td>\n",
              "      <td>[americanair, right, cue, delay]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>1</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "      <td>americanair thank got different flight chicago</td>\n",
              "      <td>[americanair, thank, got, different, flight, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "      <td>americanair leaving 20 minute late flight warn...</td>\n",
              "      <td>[americanair, leaving, 20, minute, late, fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "      <td>americanair money change flight dont answer ph...</td>\n",
              "      <td>[americanair, money, change, flight, dont, ans...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11541 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment  ...                                     msg_lemmatized\n",
              "0                     1  ...  [virginamerica, plus, youve, added, commercial...\n",
              "1                    -1  ...  [virginamerica, really, aggressive, blast, obn...\n",
              "2                    -1  ...           [virginamerica, really, big, bad, thing]\n",
              "3                    -1  ...  [virginamerica, seriously, would, pay, 30, fli...\n",
              "4                     1  ...  [virginamerica, yes, nearly, every, time, fly,...\n",
              "...                 ...  ...                                                ...\n",
              "11536                -1  ...  [americanair, flight, cancelled, flightled, le...\n",
              "11537                -1  ...                   [americanair, right, cue, delay]\n",
              "11538                 1  ...  [americanair, thank, got, different, flight, c...\n",
              "11539                -1  ...  [americanair, leaving, 20, minute, late, fligh...\n",
              "11540                -1  ...  [americanair, money, change, flight, dont, ans...\n",
              "\n",
              "[11541 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW7glxp_NXnp"
      },
      "source": [
        "# Split Data into test and train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo5Ymly5NWU7"
      },
      "source": [
        "ratio=0.6\n",
        "train = data [ : int(ratio*len(data))]\n",
        "test = data [int(ratio* len(data)):len(data)]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "3_p7ht2yPn3M",
        "outputId": "268954de-a8b4-46e3-a99c-d2c66d09d73e"
      },
      "source": [
        "train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_msg</th>\n",
              "      <th>msg_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>virginamerica plus youve added commercial expe...</td>\n",
              "      <td>[virginamerica, plus, youve, added, commercial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
              "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>virginamerica really big bad thing</td>\n",
              "      <td>[virginamerica, really, big, bad, thing]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "      <td>virginamerica seriously would pay 30 flight se...</td>\n",
              "      <td>[virginamerica, seriously, would, pay, 30, fli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
              "      <td>[virginamerica, yes, nearly, every, time, fly,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways   Not good. On hold for over an hou...</td>\n",
              "      <td>usairways good hold hour httptcowsgyckciio</td>\n",
              "      <td>[usairways, good, hold, hour, httptcowsgyckciio]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6920</th>\n",
              "      <td>1</td>\n",
              "      <td>@USAirways no worries, your flight attendant t...</td>\n",
              "      <td>usairways worry flight attendant took care</td>\n",
              "      <td>[usairways, worry, flight, attendant, took, care]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6921</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways I've been on hold for over an hour....</td>\n",
              "      <td>usairways ive hold hour well customer service ...</td>\n",
              "      <td>[usairways, ive, hold, hour, well, customer, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6922</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways - 53 minutes on hold for a reservat...</td>\n",
              "      <td>usairways 53 minute hold reservation</td>\n",
              "      <td>[usairways, 53, minute, hold, reservation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6923</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways @joyadventuremom there are breastfe...</td>\n",
              "      <td>usairways joyadventuremom breastfeeding momma ...</td>\n",
              "      <td>[usairways, joyadventuremom, breastfeeding, mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6924 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     airline_sentiment  ...                                     msg_lemmatized\n",
              "0                    1  ...  [virginamerica, plus, youve, added, commercial...\n",
              "1                   -1  ...  [virginamerica, really, aggressive, blast, obn...\n",
              "2                   -1  ...           [virginamerica, really, big, bad, thing]\n",
              "3                   -1  ...  [virginamerica, seriously, would, pay, 30, fli...\n",
              "4                    1  ...  [virginamerica, yes, nearly, every, time, fly,...\n",
              "...                ...  ...                                                ...\n",
              "6919                -1  ...   [usairways, good, hold, hour, httptcowsgyckciio]\n",
              "6920                 1  ...  [usairways, worry, flight, attendant, took, care]\n",
              "6921                -1  ...  [usairways, ive, hold, hour, well, customer, s...\n",
              "6922                -1  ...         [usairways, 53, minute, hold, reservation]\n",
              "6923                -1  ...  [usairways, joyadventuremom, breastfeeding, mo...\n",
              "\n",
              "[6924 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "l2X05TXaPn6u",
        "outputId": "41259f7b-7970-48df-96de-16d86a36d33c"
      },
      "source": [
        "test"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_msg</th>\n",
              "      <th>msg_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6924</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways #DividendRewards Urgently need to s...</td>\n",
              "      <td>usairways dividendrewards urgently need speak ...</td>\n",
              "      <td>[usairways, dividendrewards, urgently, need, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6925</th>\n",
              "      <td>-1</td>\n",
              "      <td>@usairways I've been on hold for over an hour ...</td>\n",
              "      <td>usairways ive hold hour bc cc mile arent showi...</td>\n",
              "      <td>[usairways, ive, hold, hour, bc, cc, mile, are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6926</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways I am a premium #DividendMiles #card...</td>\n",
              "      <td>usairways premium dividendmiles cardholder una...</td>\n",
              "      <td>[usairways, premium, dividendmiles, cardholder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6927</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways I bougth ticket same fligths twice ...</td>\n",
              "      <td>usairways bougth ticket fligths twice dont ref...</td>\n",
              "      <td>[usairways, bougth, ticket, fligths, twice, do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6928</th>\n",
              "      <td>-1</td>\n",
              "      <td>@USAirways @AmericanAir now this is beyond rid...</td>\n",
              "      <td>usairways americanair beyond ridiculous steeri...</td>\n",
              "      <td>[usairways, americanair, beyond, ridiculous, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11536</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
              "      <td>americanair flight cancelled flightled leaving...</td>\n",
              "      <td>[americanair, flight, cancelled, flightled, le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11537</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir right on cue with the delays👌</td>\n",
              "      <td>americanair right cue delay</td>\n",
              "      <td>[americanair, right, cue, delay]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>1</td>\n",
              "      <td>@AmericanAir thank you we got on a different f...</td>\n",
              "      <td>americanair thank got different flight chicago</td>\n",
              "      <td>[americanair, thank, got, different, flight, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
              "      <td>americanair leaving 20 minute late flight warn...</td>\n",
              "      <td>[americanair, leaving, 20, minute, late, fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>-1</td>\n",
              "      <td>@AmericanAir you have my money, you change my ...</td>\n",
              "      <td>americanair money change flight dont answer ph...</td>\n",
              "      <td>[americanair, money, change, flight, dont, ans...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4617 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment  ...                                     msg_lemmatized\n",
              "6924                 -1  ...  [usairways, dividendrewards, urgently, need, s...\n",
              "6925                 -1  ...  [usairways, ive, hold, hour, bc, cc, mile, are...\n",
              "6926                 -1  ...  [usairways, premium, dividendmiles, cardholder...\n",
              "6927                 -1  ...  [usairways, bougth, ticket, fligths, twice, do...\n",
              "6928                 -1  ...  [usairways, americanair, beyond, ridiculous, s...\n",
              "...                 ...  ...                                                ...\n",
              "11536                -1  ...  [americanair, flight, cancelled, flightled, le...\n",
              "11537                -1  ...                   [americanair, right, cue, delay]\n",
              "11538                 1  ...  [americanair, thank, got, different, flight, c...\n",
              "11539                -1  ...  [americanair, leaving, 20, minute, late, fligh...\n",
              "11540                -1  ...  [americanair, money, change, flight, dont, ans...\n",
              "\n",
              "[4617 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHIL9sRa-rRR"
      },
      "source": [
        "# TF-IDF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsGuZBkG8r-u"
      },
      "source": [
        "processed_tweets=[]\n",
        "for i in range(0, len(data)): \n",
        "    processed_tweets.append(data['clean_msg'][i])\n",
        "\n",
        "tv = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7)  \n",
        "X = tv.fit_transform(processed_tweets).toarray()\n",
        "y = data['airline_sentiment']\n",
        "y=y.astype('int')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fpYaKEAbao5"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEUOVySOba0I"
      },
      "source": [
        "# Checking For Imbalanced Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "f3n8BCEzbZ0e",
        "outputId": "1ba84511-afcd-4981-8c88-30b760ae06b7"
      },
      "source": [
        "sns.countplot(x=data['airline_sentiment'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4af1abe90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IfCypr3bsce"
      },
      "source": [
        "# Using SMOTE algorithm to handle Imbalanced Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9DyeGnlbJw0",
        "outputId": "335b37d1-baa9-4308-a192-cafab33cbd1d"
      },
      "source": [
        "smote = SMOTE()\n",
        "# fit predictor and target variable\n",
        "X, y = smote.fit_resample(X, y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxKFMyEwSrDN"
      },
      "source": [
        "# Spliting data in train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiC0Z1dsSj41"
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sit7wSuCV3bA"
      },
      "source": [
        "# Model Training on Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLO2lkT6MFry"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90g91q73V0op"
      },
      "source": [
        "# Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yySMLvhIVaMC"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCg7n2-MWj0I"
      },
      "source": [
        "# Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sznqH_ScXbvL"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYf5d0gMKsET"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnq6er60XkX_"
      },
      "source": [
        "# Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFJoMpFgXjCn"
      },
      "source": [
        "print(recall_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s80X5qEHXw3U"
      },
      "source": [
        "# Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPRXNkGJXwc7"
      },
      "source": [
        "print(precision_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "625L7FqUd_3i"
      },
      "source": [
        "## Precision will be the best evaluation metric for airline sentiment analysis because the airline is more concerned about the 'negative' class and the more number of 'False Positives' will be a problem for the airline. So the model should minimize the number of false positives.As precision = TP/(TP+FP)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca9ws0J_fA0l"
      },
      "source": [
        "## The less number of false positives means the precision is higher that means the model is doing great."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUnNJxY7YEuB"
      },
      "source": [
        "# F1- Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3xXHbvOYIzq"
      },
      "source": [
        "print(f1_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAdzaApAZX60"
      },
      "source": [
        "# ROC-AUC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUkl8zItYTlR"
      },
      "source": [
        "metrics.plot_roc_curve(model, X_test, y_test)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2WHW40AX9fZ"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHgzh7OU8sBW"
      },
      "source": [
        "all_words = ' '.join([text for text in data['clean_msg']])\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5a8EMxnWROD"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ks8JQGzWQL_"
      },
      "source": [
        "### Create a Pickle file using serialization \n",
        "pickle_out = open(\"model.pkl\",\"wb\")\n",
        "pickle.dump(model, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}